# ============================================================
# Disaster Literacy RAG System - Environment Configuration
# ============================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control (it's in .gitignore)

# ============================================================
# ONLINE LLM API KEYS (Optional - only needed for online mode)
# ============================================================
# Get Google API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Get OpenRouter API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter model to use (free tier model shown)
OPENROUTER_MODEL=qwen/qwen-2.5-72b-instruct:free

# Default online provider: "google" or "openrouter"
ONLINE_LLM_PROVIDER=google

# ============================================================
# SYSTEM CONFIGURATION
# ============================================================
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================
# EMBEDDING MODEL (for offline mode)
# ============================================================
# Sentence transformer model for embeddings
# This model is downloaded automatically on first run
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

# ============================================================
# TESSERACT OCR PATH (Required for PDF OCR)
# ============================================================
# Windows default path (adjust if installed elsewhere)
TESSERACT_CMD=C:\\Program Files\\Tesseract-OCR\\tesseract.exe

# Linux/Mac: usually just "tesseract" (in PATH)
# TESSERACT_CMD=tesseract

# ============================================================
# KNOWLEDGE BASE SETTINGS
# ============================================================
# Chunk size for document splitting (in characters)
KB_CHUNK_SIZE=400

# Overlap between chunks (in characters)
KB_CHUNK_OVERLAP=75

# ============================================================
# ONLINE MODE SETTINGS
# ============================================================
# Number of chunks to retrieve for online mode
ONLINE_TOP_K_RETRIEVAL=20

# Maximum tokens for online LLM responses
ONLINE_MAX_LLM_TOKENS=4096

# ============================================================
# OPTIONAL: ADVANCED OFFLINE MODE SETTINGS
# ============================================================
# Uncomment and customize these if you want to override defaults

# Economy mode settings (for lower-spec systems)
# OFFLINE_ECONOMY_TOP_K_RETRIEVAL=2
# OFFLINE_ECONOMY_MAX_LLM_TOKENS=512
# OFFLINE_LLM_MODEL_PATH_ECONOMY=./models/llama-2-7b-chat.Q4_K_M.gguf

# Power mode settings (for higher-spec systems)
# OFFLINE_POWER_TOP_K_RETRIEVAL=6
# OFFLINE_POWER_MAX_LLM_TOKENS=1024
# OFFLINE_LLM_MODEL_PATH_POWER=./models/qwen2-7b-instruct-q4_k_m.gguf

# ============================================================
# OPTIONAL: TRANSLATION SETTINGS
# ============================================================
# Enable translation for non-English queries (Google provider only)
# Set to "true" to enable, "false" to disable
# ENABLE_TRANSLATION=false

# ============================================================
# OPTIONAL: DEBUGGING
# ============================================================
# Enable debug mode for verbose logging
# DEBUG_MODE=false
